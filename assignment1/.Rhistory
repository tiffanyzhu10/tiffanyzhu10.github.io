letters[sleep_data[,3]]
levels(sleep_data[,3])
sleep_data
levels(sleep_data[,3]) = LETTERS[sleep_data[,3]]
sleep_data
sleep
birthdays = tibble(first = "Adelaide", "Gavrila", "Katia", "Marius", "Marie", "Jonathan",
last = "Desrochers", "Isakov", "Partridge", "Berenyi", "Lu", "Bing")
library(tidyverse)
practice = tibble(name = "Alice Liu", "Marie Zhang"; age = 14, 27)
practice = tibble(name = "Alice Liu", "Marie Zhang", age = 14, 27)
practice
?tibble
diamonds
practice = tibble(name = "Alice Liu, Marie Zhang", age = "14, 27")
practice
vignette(tibble)
vignette("tibble")
practice = tibble(name = list("Alice Liu", "Marie Zhang"), age = c(14, 27))
practice
practice = tibble(name = c("Alice Liu", "Marie Zhang"), age = c(14, 27))
practice
birthdays = tibble(
first = c("Adelaide", "Ganya", "Katia", "Marius", "Marie", "Jonathan"),
last = c("Desrochers", "Isakov", "Partridge", "Berenyi", "Lu", "Bing"),
birthday = c("1999-07-22", "1994-02-11", "1997-09-07", "1997-12-14", "1999-01-23", "1998-05-31"),
relationship = c("classmate", "friend", "associate", "coworker", "sister", "cousin"),
YOR = c(2, 0.5, 5, 8, 7, 3),
city = c("Santa Clara", "San Jose", "Saratoga", "Los Gatos", "Sunnyvale", "Fremont")
)
birthdays
parse_date(birthdays[,3])
birthdays[,3]
guess_parser(birthdays[,3])
birthdays = tibble(
first = c("Adelaide", "Ganya", "Katia", "Marius", "Marie", "Jonathan"),
last = c("Desrochers", "Isakov", "Partridge", "Berenyi", "Lu", "Bing"),
birthday = c(1999-07-22, 1994-02-11, 1997-09-07, 1997-12-14, 1999-01-23, 1998-05-31),
relationship = c("classmate", "friend", "associate", "coworker", "sister", "cousin"),
YOR = c(2, 0.5, 5, 8, 7, 3),
city = c("Santa Clara", "San Jose", "Saratoga", "Los Gatos", "Sunnyvale", "Fremont")
+ )
birthdays = tibble(
first = c("Adelaide", "Ganya", "Katia", "Marius", "Marie", "Jonathan"),
last = c("Desrochers", "Isakov", "Partridge", "Berenyi", "Lu", "Bing"),
birthday = c(1999-07-22, 1994-02-11, 1997-09-07, 1997-12-14, 1999-01-23, 1998-05-31),
relationship = c("classmate", "friend", "associate", "coworker", "sister", "cousin"),
YOR = c(2, 0.5, 5, 8, 7, 3),
city = c("Santa Clara", "San Jose", "Saratoga", "Los Gatos", "Sunnyvale", "Fremont"))
birthdays
birthdays = tibble(
first = c("Adelaide", "Ganya", "Katia", "Marius", "Marie", "Jonathan"),
last = c("Desrochers", "Isakov", "Partridge", "Berenyi", "Lu", "Bing"),
birthday = c("1999-07-22", "1994-02-11", "1997-09-07", "1997-12-14", "1999-01-23", "1998-05-31"),
relationship = c("classmate", "friend", "associate", "coworker", "sister", "cousin"),
YOR = c(2, 0.5, 5, 8, 7, 3),
city = c("Santa Clara", "San Jose", "Saratoga", "Los Gatos", "Sunnyvale", "Fremont")
)
birthdays
as.date(birthdays[[,3]])
parse_date(birthdays[[,3]])
birthdays[[,3]]
birthdays[,3]
parse_date(birthdays[,3])
guess_parser(birthdays[,3])
as.Date(birthdays[,3])
?as.Date
as.Date(birthdays[,3], format="%Y-%m-%d")
url.info <- "https://web.stanford.edu/~hastie/ElemStatLearn/datasets/nci.info.txt"
info <- read_table(url.info, skip=14, col_names=F)
url.data <- "https://web.stanford.edu/~hastie/ElemStatLearn/datasets/nci.data"
microarray <- read_table(url.data, col_names=info$X1)
library(tidyverse)
url.info <- "https://web.stanford.edu/~hastie/ElemStatLearn/datasets/nci.info.txt"
info <- read_table(url.info, skip=14, col_names=F)
url.data <- "https://web.stanford.edu/~hastie/ElemStatLearn/datasets/nci.data"
microarray <- read_table(url.data, col_names=info$X1)
microarray
?apply
mutate(microarray, st_dev = apply(microarray, 1, sd))
subset = mutate(microarray, st_dev = apply(microarray, 1, sd))
subset = arrange(subset, desc(st_dev))
(subset = select(subset, row_number() <= 50))
(subset = filter(subset, row_number() <= 50))
subset$st_dev
?heatmap
heatmap(subset, asp = 0.2)
heatmap(subset$st_dev, asp = 0.2)
ggplot(subset, aes(x = st_dev)) + geom_histogram()
ggplot(subset, aes(x = st_dev)) + geom_histogram(binwidth = 0.01)
ggplot(subset, aes(x = st_dev)) + geom_histogram(binwidth = 0.05)
ggsave("stdevhist.jpg")
subset_mat = matrix(subset, 50, 65)
subset_mat
subset_mat[5,5]
subset_mat[1,1]
subset_mat[1,]
subset_mat = data.matrix(subset)
subset_mat
heatmap(subset_mat, asp = 0.2)
?heatmap
heatmap(subset_mat, Rowv = NA, Colv = NA, asp = 0.2)
ggsave("heatmap.jpg")
?heatmap
heatmap(subset_mat, Rowv = NA, Colv = NA, scale = "row", asp = 0.2)
heatmap(subset_mat, Rowv = NA, Colv = NA, scale = "col", asp = 0.2)
heatmap(subset_mat, Rowv = NA, Colv = NA, asp = 0.2)
heatmap(subset_mat, Rowv = NA, Colv = NA, scale = "column", asp = 0.2)
heatmap(subset_mat, Rowv = NA, Colv = NA, asp = 0.2)
ggsave("heatmap.jpg")
heatmap(subset_mat, Rowv = NA, Colv = NA, asp = 0.2)
ggsave("heatmap.jpg")
ggsave("heatmap.jpg")
?data.matrix
subset_mat = data.matrix(subset$-st_dev)
subset_mat_graph = select(subset_mat, -st_dev)
subset_mat_graph = select(subset, -st_dev)
subset_mat_graph = data.matrix(subset_mat_graph)
subset_mat_graph = matrix(subset_mat_graph, nrow = 64, ncol = 50, byrow = TRUE)
subset_mat_graph
subset_mat_graph = select(subset, -st_dev)
> subset_mat_graph = data.matrix(subset_mat_graph)
subset_mat_graph = select(subset, -st_dev) subset_mat_graph = data.matrix(subset_mat_graph)
subset_mat_graph = select(subset, -st_dev)
subset_mat_graph = data.matrix(subset_mat_graph)
subset_mat_graph
heatmap(subset_mat_graph, Rowv = NA, Colv = NA, asp = 0.2)
subset_mat_graph = select(subset, -st_dev)
subset_mat_graph = data.matrix(subset_mat_graph)
library(tidyverse)
adverts = read_csv("http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv")
set.seed(123)
row_indices = sample(seq(1, 200), 150)
training = slice(adverts, row_number(row_indices))
training
mult_reg = lm(log(sales) ~ log(TV) + radio + newspaper)
mult_reg = lm(log(sales) ~ log(TV) + radio + newspaper, data = training)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(pred = exp(pred), resid = sales - pred)
?add_predictions
training %>% add_predictions(mult_reg) %>% mutate(pred = exp(pred), resid = sales - pred)
mult_reg = lm(log(sales) ~ log(TV), data = training)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(pred = exp(pred), resid = sales - pred)
library(modelr)
mult_reg = lm(log(sales) ~ log(TV) + radio + newspaper, data = training)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(pred = exp(pred), resid = sales - pred)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
mult_reg = lm(sales ~ TV + radio + newspaper, data = training)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(pred = exp(pred), resid = sales - pred)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
training_mult
training_mult = training %>% add_predictions(mult_reg) %>% mutate(pred = pred - TV - newspaper - radio, resid = sales - pred)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
training_mult = training %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
training_mult$pred
mult_reg = lm(formula = sales ~ TV + radio + newspaper, data = training)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
training_mult$pred
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred))
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
?geom_smooth
?geom_line
?geom_smooth
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred), formula = sales ~ TV + radio + newspaper)
training_mult
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred), formula = y ~ TV + radio + newspaper)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred))
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred), fill = NA)
mult_reg = lm(formula = sales ~ TV + radio + newspaper, data = training
training_mult = training %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred), fill = NA)
mult_reg = lm(formula = sales ~ TV + radio + newspaper, data = training)
training_mult = training %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
ggplot(training_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred), fill = NA)
ggsave("multreg.jpg")
summary(mult_reg)
training_mult$resid
regression = lm(log(sales) ~ log(TV), data = training)
training_regress = training %>% add_predictions(regression) %>% mutate(pred = exp(pred), resid = sales - pred)
ggplot(training_regress) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
training_regress$resid
training_regress = mutate(training_regress, resid_sq = resid^2)
sqrt(sum(training_regress$resid_sq))
mult_reg = lm(formula = sales ~ TV + radio + newspaper, data = training)
test_mult = test %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
test = slice(adverts, -row_number(row_indices))
mult_reg = lm(formula = sales ~ TV + radio + newspaper, data = training)
test_mult = test %>% add_predictions(mult_reg) %>% mutate(resid = sales - pred)
ggplot(test_mult) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_smooth(color = "red", aes(x = TV, y = pred), fill = NA)
ggsave("multreg-test.jpg")
test_mult
test_mult = mutate(test_mult, resid_sq = resid^2)
sqrt(sum(test_mult$resid))
sqrt(sum(test_mult$resid_sq))
test_regress = test %>% add_predictions(regression) %>% mutate(pred = exp(pred), resid = sales - pred)
ggplot(test_regress) + geom_point(aes(x = TV, y = sales), alpha = 0.1) + geom_line(color = "red", aes(x = TV, y = pred))
ggsave("simplereg-test.jpg")
test_regress$pred
test_regress = mutate(test_regress, resid_sq = resid^2)
sqrt(sum(test_regress$resid_sq))
sqrt(sum(test_regress$resid_sq)/n())
n()
sqrt(sum(test_regress$resid_sq)/50)
test_mult$resid_sq/50
sqrt(sum(test_mult$resid_sq)/50)
library(tidyverse)
ggplot(diamonds, aes(carat, price)) +
geom_point(aes(color = clarity)) +
geom_smooth(se = FALSE) +
labs(title = "Price of diamonds generally increases with weight")
p1 <- ggplot(diamonds,aes(x=carat,y=price))+geom_point()
p2 <- p1 + theme_bw()
p2
p1 <- ggplot(diamonds,aes(x=carat,y=price))+geom_point()
p2 <- p1 + theme_classic()
p2
install.packages("rmarkdown")
library(tidyverse)
smaller <- diamonds %>%
filter(carat <= 2.5)
smaller %>%
ggplot(aes(carat)) +
geom_freqpoly(binwidth = 0.01)
install.packages(tinytex)
install.packages(tinytex)
smaller
?knitr
twenty = smaller %>% arrange(desc(x)) %>% select(row_number() <= 20)
library(tidyverse)
show_missings <- function(df) {
cat("Missing values: "
, sum(is.na(df)),
"\n"
, sep = "")
invisible(df)
}
table1
show_missings(table1)
table1 %>% show_missings() %>% show_missings()
dim(show_missings(diamonds))
f <- function(x) {
x + y
}
f(1)
y = 2
f(1)
x = 4
f(1)
evenodd = function(x) {
if (x = 0)
return("zero")
else if (x % 2 = 0)
return("even")
else
return("odd")
}
evenodd = function(x) {
if (x == 0)
return("zero")
else if (x % 2 == 0)
return("even")
else
return("odd")
}
evenodd = function(x) {
if (x == 0)
return(0)
else if (x % 2 == 0)
return("even")
else
return("odd")
}
evenodd = function(x) {
if (x == 0) {
return(0)
}
else if (x % 2 == 0) {
return("even")
}
else {
return("odd")
}
}
evenodd = function(x) {
if (x == 0) {
return(0)
} else if (x % 2 == 0) {
return("even")
} else {
return("odd")
}
}
evenodd = function(x) {
if (x == 0) {
return(0)
}
if (x % 2 == 0) {
return("even")
}
else {
return("odd")
}
}
evenodd = function(x) {
if (x == 0) {
return(0)
}
if (x %% 2 == 0) {
return("even")
}
else {
return("odd")
}
}
evenodd(2)
evenodd(5)
evenodd(0)
col_summary <- function(df, fun) {
out <- vector("double"
, length(df))
for (i in seq_along(df)) {
out[i] <- fun(df[[i]])
}
out
}
(df = table1[, -1])
col_summary(df, mean)
df %>% map_dbl(mean)
rus_raw
testing = read_csv("/Users/tiffanyzhu/Desktop/Stanford/Frosh/Stats\ 195/WID_fulldataset_RU/Data/WID_RU_InequalityData.csv")
library(tidyverse)
testing = read_csv("/Users/tiffanyzhu/Desktop/Stanford/Frosh/Stats\ 195/WID_fulldataset_RU/Data/WID_RU_InequalityData.csv")
testing
poland = read_csv("/Users/tiffanyzhu/Desktop/Stanford/Frosh/Stats\ 195/PolandInequality.csv")
poland
?filter
pol_raw = read_csv("/Users/tiffanyzhu/Desktop/Stanford/Frosh/Stats\ 195/PolandInequality.csv")
pol_raw
?select
?rename
?gather
library(tidyverse)
?gather
?spread
?gather
?apply
library(tidyverse)
library(modelr)
data = read_csv("/Users/tiffanyzhu/Downloads/downloads/country_hsproduct4digit_year.csv")
data$hs_product_name_short_en
data %>% filter(location_code = "RUS")
data %>% select(location_code = "RUS")
?filter
data %>% filter(location_code == "RUS")
data %>% filter(hs_product_name_short_en == "Petroleum oils, crude")
data_new = data %>% filter(hs_product_name_short_en == "Petroleum oils, crude" || hs_product_name_short_en == "Petroleum oils, refined" || hs_product_name_short_en == "Petroleum gases")
data_new = data %>% filter(hs_product_name_short_en == "Petroleum oils, crude" || hs_product_name_short_en == "Petroleum oils, refined")
data_new = data %>% filter(hs_product_name_short_en == "Petroleum oils, crude" | hs_product_name_short_en == "Petroleum oils, refined" | hs_product_name_short_en == "Petroleum gases")
?write_csv
write_csv(data_new, /Users/tiffanyzhu/Dropbox/Chapter 4 Data/Updated charts/Charts in progress)
write_csv(data_new, "/Users/tiffanyzhu/Dropbox/Chapter 4 Data/Updated charts/Charts in progress")
?file.path
write_csv(data_new, "/Users/tiffanyzhu/Dropbox/Chapter 4 Data/Updated charts/Charts in progress", append = FALSE, col_names = !append)
write_csv(data_new, "OilGas.csv", append = FALSE, col_names = !append)
?write_csv
write_csv(data_new, "OilGas.csv", na = "NA", append = FALSE, col_names = !append)
write_csv(data_new, "OilGas.csv")
data_new = data %>% filter(location_name_short_en = "Russia" | location_name_short_en = "Brazil" | location_name_short_en = "India" | location_name_short_en = "China" | location_name_short_en = "South Africa" | location_name_short_en = "United States")
data_new = data %>% filter(location_name_short_en == "Russia" | location_name_short_en == "Brazil" | location_name_short_en == "India" | location_name_short_en == "China" | location_name_short_en == "South Africa" | location_name_short_en == "United States")
View(data_new)
data_new = data %>% filter(location_name_short_en == "Russia" | location_name_short_en == "Brazil" | location_name_short_en == "India" | location_name_short_en == "China" | location_name_short_en == "South Africa" | location_name_short_en == "United States of America")
data_new = data %>% filter(location_name_short_en == "Russian Federation" | location_name_short_en == "Brazil" | location_name_short_en == "India" | location_name_short_en == "China" | location_name_short_en == "South Africa" | location_name_short_en == "United States of America")
View(data_new)
write_csv(data_new, "OilGasBRICSUS.csv")
data_EU = data %>% filter(location_name_short_en == "Austria" | location_name_short_en == "Belgium" | location_name_short_en == "Bulgaria" | location_name_short_en == "Croatia" | location_name_short_en == "Cyprus" | location_name_short_en == "Czechia" | location_name_short_en == "Denmark" | location_name_short_en == "Estonia" | location_name_short_en == "Finland" | location_name_short_en == "France" | location_name_short_en == "Germany" | location_name_short_en == "Greece" | location_name_short_en == "Hungary" | location_name_short_en == "Ireland" | location_name_short_en == "Italy" | location_name_short_en == "Latvia" | location_name_short_en == "Lithuania" | location_name_short_en == "Luxembourg" | location_name_short_en == "Malta" | location_name_short_en == "Netherlands" | location_name_short_en == "Poland" | location_name_short_en == "Portugal" | location_name_short_en == "Romania" | location_name_short_en == "Slovakia" | location_name_short_en == "Slovenia" | location_name_short_en == "Spain" | location_name_short_en == "Sweden" | location_name_short_en == "United Kingdom")
data_EU = data %>% filter(location_name_short_en == "Austria" | location_name_short_en == "Belgium" | location_name_short_en == "Bulgaria" | location_name_short_en == "Croatia" | location_name_short_en == "Cyprus" | location_name_short_en == "Czech Republic" | location_name_short_en == "Denmark" | location_name_short_en == "Estonia" | location_name_short_en == "Finland" | location_name_short_en == "France" | location_name_short_en == "Germany" | location_name_short_en == "Greece" | location_name_short_en == "Hungary" | location_name_short_en == "Ireland" | location_name_short_en == "Italy" | location_name_short_en == "Latvia" | location_name_short_en == "Lithuania" | location_name_short_en == "Luxembourg" | location_name_short_en == "Malta" | location_name_short_en == "Netherlands" | location_name_short_en == "Poland" | location_name_short_en == "Portugal" | location_name_short_en == "Romania" | location_name_short_en == "Slovakia" | location_name_short_en == "Slovenia" | location_name_short_en == "Spain" | location_name_short_en == "Sweden" | location_name_short_en == "United Kingdom")
write_csv(data_EU, "OilGasEU.csv")
favorite = 'Kuzmanovic'
data = read_csv("Downloads/country_hsproduct4digit_year.tab")
library(readr)
data = read_csv("Downloads/country_hsproduct4digit_year.tab")
View(data)
?read_csv
data = read_csv("Downloads/country_hsproduct4digit_year.tab", "\t")
data = read_delim("Downloads/country_hsproduct4digit_year.tab", "\t")
locations = read_delim("Downloads/location.tab", "\t")
?merge
View(data)
View(locations)
data_locations = merge(data, locations)
stop
stop()
?filter
?select
library(dplyr)
?select
View(data)
?filter
View(locations)
data_BRICSUS = filter(data, "location_id==32" | "location_id==43" | "location_id==104" | "location_id==186" | "location_id==231" | "location_id==246")
data_BRICSUS = filter(data, location_id=="32" | location_id=="43" | location_id=="104" | location_id=="186" | location_id=="231" | location_id=="246")
data_BRICSUS$location_code
products = read_delim("Downloads/hs_product", "\t")
products = read_delim("Downloads/hs_product.tab", "\t")
View(products)
data_BRICSUS_prods = merge(data_BRICSUS, products)
View(data_BRICSUS_prods)
data_BRICSUS = filter(data_locations, location_id=="32" | location_id=="43" | location_id=="104" | location_id=="186" | location_id=="231" | location_id=="246")
data_BRICSUS_prods = merge(data_BRICSUS, products)
View(data_BRICSUS_prods)
View(data_BRICSUS)
data_BRICSUS_prods = merge(data_BRICSUS, products)
test = merge(data_BRICSUS, products)
View(test)
View(test)
View(products)
View(data_BRICSUS)
?merge
View(products)
View(data_BRICSUS_prods)
View(data_BRICSUS)
View(products)
products = read_delim("Downloads/hs_product.tab", "\t")
data_BRICSUS_prods = merge(data_BRICSUS, products)
data_locations = merge(data, locations)
View(locations)
View(data_locations)
data_BRICSUS = filter(data_locations, location_name_short_en="Brazil", location_name_short_en="China", location_name_short_en="India", location_name_short_en="Russian Federation", location_name_short_en="United States", location_name_short_en="South Africa")
data_BRICSUS = filter(data_locations, location_name_short_en=="Brazil", location_name_short_en=="China", location_name_short_en=="India", location_name_short_en=="Russian Federation", location_name_short_en=="United States", location_name_short_en=="South Africa")
data_BRICSUS = filter(data_locations, location_name_short_en=="Brazil" | location_name_short_en=="China" | location_name_short_en=="India" | location_name_short_en=="Russian Federation" | location_name_short_en=="United States" | location_name_short_en=="South Africa")
View(locations)
data_BRICSUS = filter(data_locations, location_name_short_en=="Brazil" | location_name_short_en=="China" | location_name_short_en=="India" | location_name_short_en=="Russian Federation" | location_name_short_en=="United States of America" | location_name_short_en=="South Africa")
data_BRICSUS_prods = merge(data_BRICSUS, products)
data_BRICSUS$hs_product_code
data_BRICSUS_prods = merge(data_BRICSUS, products, by.x="hs_product_code", by.y="hs_product_code")
View(data_BRICSUS_prods)
data_BRICSUS_prods = merge(data_BRICSUS, products, by="hs_product_code")
View(data_BRICSUS_prods)
write.csv(data_BRICSUS_prods, "Downloads/data_BRICSUS_prods.csv")
data_BRICSUS_prods_filt = filter(data_BRICSUS_prods, hs_product_name_short_en=="Petroleum oils, crude", hs_product_name_short_en=="Petroleum oils, refined", hs_product_name_short_en=="Petroleum gases")
?filter
data_BRICSUS_prods_filt = filter(data_BRICSUS_prods, hs_product_name_short_en=="Petroleum oils, crude" | hs_product_name_short_en=="Petroleum oils, refined" | hs_product_name_short_en=="Petroleum gases")
write.csv(data_BRICSUS_prods_filt, "Downloads/data_BRICSUS_prods_filt.csv")
data_rus = filter(data, location_code=="RUS")
write.csv(data_rus, "Downloads/data_rus.csv")
data_BRICSUS_prods_filt_rus = filter(data_BRICSUS_prods_filt, location_code=="RUS")
view(data_BRICSUS_prods_filt_rus)
View(data_BRICSUS_prods_filt_rus)
write.csv(data_BRICSUS_prods, "Downloads/data_BRICSUS_prods.csv")
View(data_BRICSUS)
max(data_BRICSUS$year)
write_csv(data_BRICSUS, "Downloads/data_BRICSUS.csv")
data_rus_prod = merge(data_rus, products)
View(data_rus)
write_csv(data_rus_prod, "Downloads/data_rus_prod.csv")
filter(data, location_code=="RUS", hs_product_code="2709")
filter(data, location_code=="RUS", hs_product_code=="2709")
library(readr)
country_hsproduct4digit_year <- read_delim("Downloads/country_hsproduct4digit_year.tab",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(country_hsproduct4digit_year)
data = country_hsproduct4digit_year
filter(data, country_code=="RUS", hs_product_code=="2709")
filter(data, country_code=="RUS" | hs_product_code=="2709")
library(dplyr)
filter(data, country_code=="RUS" | hs_product_code=="2709")
filter(data, location_code=="RUS" | hs_product_code=="2709")
locations = read.csv("Downloads/location.csv")
library(readr)
locations = read.csv("Downloads/location.csv")
locations = read.delim("Downloads/location.tab", "\t")
?read.delim
locations = read_delim("Downloads/location.tab", "\t")
locations
?select
locations = select(locations, locations$location_code, locations$location_name_short_en)
select(locations, locations$location_code, locations$location_name_short_en)
select(locations$location_code, locations$location_name_short_en)
select(locations, locations$location_code:locations$location_name_short_en)
locations = select(locations, -1, -4, -5)
locations
data_locs = merge(data, locations)
View(locations)
filter(data_locs, location_name_short_en=="Russian Federation" | hs_product_code=="2709")
filter(data_locs, location_code=="RUS" | hs_product_code=="2709")
filter(data_locs, location_code=="RUS" & hs_product_code=="2709")
filter(data, location_code=="RUS" & hs_product_code=="2709")
filter(data, location_code=="USA" & hs_product_code=="2709")
last(filter(data, location_code=="USA" & hs_product_code=="2709"))
data_rus = filter(data, location_code=="RUS" & hs_product_code=="2709")
View(data_rus)
plot(cars)
install.packages("xlsx")
install.library("xlsx")
install.packages("xlsx")
remove.packages("xlsx")
remove.packages("xlsxjars")
install.packages("xlsx")
install.packages("xlsx")
remove.packages("xlsxjars")
remove.packages("rJava")
remove.packages("grDevices")
remove.packages("utils")
install.packages("xlsx")
install.packages("grDevices")
rm(list=ls())
load("~/Documents/GitHub/tiffanyzhu10.github.io/assignment1/.RData")
rm(list=ls())
setwd("~/Documents/GitHub/tiffanyzhu10.github.io/assignment1")
load("~/Documents/GitHub/tiffanyzhu10.github.io/assignment1/.RData")
rm(list=ls())
